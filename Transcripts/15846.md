# DevOps and Kubernetes Notes

### 1. **Azure DevOps Overview**
   - Azure DevOps provides multiple services for development workflows, including **Pipelines**, **Repos**, **Artifacts**, and **Test Plans**.
   - **Artifacts**: Azure DevOps offers storage for artifactory management (up to 2GB free), used for storing project binaries and dependencies.
   - **Test Plans**: These allow integration with automation tools or manual testing. Test cases can be written and assigned to specific users within Azure DevOps, and the results (pass/fail) are stored in the system.

### 2. **Kubernetes Overview**
   - Kubernetes is a **container orchestration platform** designed to manage containers across multiple nodes.
   - Kubernetes provides key features such as:
     - **Automatic deployment** and **scaling**.
     - **Load balancing**.
     - **Rollout and rollback** capabilities for versioning deployments without downtime.

### 3. **Kubernetes Cluster Deployment on Cloud**
   - **Supported Cloud Platforms**: Kubernetes clusters can be deployed on major cloud platforms like AWS, Azure, and Google Cloud.
     - **AWS**: Elastic Kubernetes Service (EKS)
     - **Azure**: Azure Kubernetes Service (AKS)
     - **Google Cloud**: Google Kubernetes Engine (GKE)

### 4. **Azure Kubernetes Service (AKS) Setup**
   - **Cluster Creation**:
     - **Resource Group**: Define a resource group where the Kubernetes cluster will reside.
     - **Cluster Environment**: Choose between **Dev/Test**, **Production Standard**, or **Production Enterprise** environments depending on the nature of the workload.
   - **Pricing Tiers**:
     - AKS master services (e.g., scheduler, controller, etc.) are free, but you need to pay for the number of nodes in the cluster.
   - **Version Control**: Kubernetes supports multiple versions, and users can upgrade or downgrade versions based on their needs.

### 5. **Kubernetes Cluster Configuration**
   - **Node Pool**: Users can select different node types such as general-purpose, compute-optimized, or memory-optimized, based on workload requirements.
     - Nodes can host a certain number of **Pods** (containers). Each pod runs containers and can be deployed up to a maximum defined capacity.
   - **Public/Private Clusters**:
     - Public clusters are accessible over the internet, whereas private clusters are only available within private networks.
   - **Container Networking**: To ensure communication between containers and nodes, Kubernetes uses networking policies like **Azure CNI** or **Calico** for handling IP assignment and traffic.

### 6. **Security and Scaling**
   - **Security Patching**: Kubernetes offers automated patch management, or users can manually handle security through node images.
   - **Scaling**: Kubernetes automatically scales applications up and down based on workload demand. Users can also manually scale resources as needed.

### 7. **Key Kubernetes Components**
   - **API Server**: Handles communication between the user and the cluster.
   - **Controller**: Manages the cluster's state, ensuring the desired number of replicas (identical pods) are always maintained.
   - **Scheduler**: Assigns workloads (pods) to nodes based on resource availability.
   - **Kubelet**: Agent running on each node, responsible for communication between nodes and the API server, ensuring the node's state matches the desired configuration.
   - **Kube-proxy**: Handles communication between nodes and containers using networking protocols (TCP/UDP).

### 8. **Monitoring and Managing Clusters**
   - **CLI Tools**:
     - **kubectl (cube control)**: Command-line tool for managing Kubernetes clusters.
     - **Azure CLI**: Used for interacting with Azure services, including AKS.
   - **Cloud Shell**: Provides an environment to run Kubernetes commands directly in Azure.

### 9. **Scaling and Load Management**
   - Kubernetes supports **auto-scaling**, allowing the cluster to automatically adjust resources based on the application’s needs. You can run up to 110 pods per node by default, but this can be scaled depending on the node’s capacity.

### 10. **User Interaction**
   - Users can interact with Kubernetes clusters through either the **command-line interface (CLI)** or a **user interface** such as the Kubernetes dashboard.

### 11. **Key Considerations in Kubernetes**
   - **Cluster Size**: Adjust the node and pod sizes according to workload requirements. Larger clusters benefit from using more advanced networking and security configurations.
   - **Pod Communication**: Kubernetes handles communication between containers (pods) across nodes through policies and proxy configurations.
   - **Private Networks**: For critical applications, running Kubernetes in private clusters with restricted IP access enhances security.

# DevOps Notes: Kubernetes Cluster Management

### Introduction
- **Command Line Interface (CLI)**: Essential for interacting with Kubernetes (K8s) clusters.
- **kubectl**: Key CLI tool for Kubernetes. Ensure it's installed and configured on your system.

### Kubernetes Nodes and Clusters
- **Node**: A worker machine in Kubernetes. Each node contains the services necessary to run pods.
- **Node Configuration**:
  - Minimum Node Count: 2 nodes.
  - Maximum Node Count: 3 nodes.
  - Each node can handle up to **110 pods** by default.

### Node and Pod Management
- **Scaling**: When the total pod count exceeds node capacity (e.g., 220 pods for two nodes), additional nodes are created to handle the load.
- **View Node Information**:
  - Command: `kubectl get nodes`
  - Lists all nodes in the cluster with details like uptime, Kubernetes version, etc.
  - Detailed information: `kubectl get nodes --show-labels` shows node labels such as OS type, disk type, etc.

### Kubernetes Commands Overview
1. **Get Nodes**: `kubectl get nodes`
2. **Get Node Labels**: `kubectl get nodes --show-labels`
3. **Get Pods**: `kubectl get pods`
4. **Get Services**: `kubectl get svc` or `kubectl get service`
5. **Get All Resources**: `kubectl get all`

### Declarative vs Imperative Management
- **Imperative**: Directly issuing commands to the cluster. Example: `kubectl create deployment`.
- **Declarative**: Using manifest files (YAML format) to define desired cluster states.

### Creating Deployments
- **kubectl create deployment**:
  - Command: `kubectl create deployment [deployment-name] --image=[image-name] --replicas=[number]`
  - Example: `kubectl create deployment nginx-deployment --image=nginx --replicas=5`
  - Key parameters:
    - **Image**: Docker image to deploy.
    - **Replicas**: Number of identical copies of the pod.
    - **Ports**: Defined to expose the application.

### Deployment Information
- **Get Deployment Details**: 
  - Command: `kubectl describe deployment [deployment-name]`
  - Shows replica count, pod statuses, and associated container ports.

### Running Deployments and Pods
- **Run Deployment**:
  - Command: `kubectl run [deployment-name] --image=[image-name] --port=[port-number]`
  - After running a deployment, Kubernetes creates the defined number of replicas (pods).
  
- **View Running Pods**:
  - Command: `kubectl get pods` to view the status of each replica.

### Exposing Deployments
- **Kubernetes Services**:
  - **Service**: A way to expose applications running on a set of pods.
  - **Types of Services**:
    1. **ClusterIP**: Default service type, only accessible within the cluster.
    2. **NodePort**: Exposes the service on each node's IP at a static port.
    3. **LoadBalancer**: Automatically provisions an external load balancer for the service.
  
- **Expose a Deployment**:
  - Command: `kubectl expose deployment [deployment-name] --type=[service-type] --port=[port-number]`
  - Example: `kubectl expose deployment nginx-deployment --type=LoadBalancer --port=80`
  - This command creates a service that exposes the deployment to external traffic.

### Example of Service Exposure:
- **Load Balancer Service**:
  - Use `kubectl get svc` to retrieve the external IP after deploying with a LoadBalancer.
  - Once the external IP is assigned, you can access the application using the public IP address.

### Conclusion
- **Best Practices**:
  - Always check node and pod limits to scale clusters effectively.
  - Understand the difference between imperative and declarative methods.
  - Use services like **LoadBalancer** to expose applications to the internet.
  - Remember to use `kubectl get all` to get an overview of all resources in the Kubernetes cluster.

---

This concludes the notes on managing Kubernetes clusters using `kubectl`. Key focus areas include deployment, scaling, and service exposure for running applications in a cloud environment.

# DevOps Notes Summary

## 1. **Pod Information Retrieval**
   - Use `describe pod [pod name]` to retrieve detailed information about a specific pod.
   - Information includes:
     - Pod status
     - IP address assigned
     - Start time
     - Node and agent where the pod is running
     - Service associated with the pod

## 2. **Viewing Pod Logs**
   - Use `kubectl logs [pod name]` to access logs for a particular pod.
   - Logs provide details about events and activities within the pod.

## 3. **Viewing Kubernetes Events**
   - Use `kubectl get events` to list all events related to various stages of pod execution.
   - Useful for understanding the sequence of operations or troubleshooting issues.

## 4. **Imperative vs. Declarative Deployment Methods**
   - **Imperative Method:**
     - Deploy applications using direct commands, e.g., `kubectl create`.
     - Drawbacks include lack of reusability and hard coding of values for each environment.
   - **Declarative Method:**
     - Use configuration files (YAML format) to manage deployments.
     - More structured, reusable, and customizable across environments.
     - File structure includes the following properties:
       - `apiVersion`
       - `kind`
       - `metadata`
       - `spec`

## 5. **YAML File Structure**
   - YAML format used for declarative deployments should include:
     - **API Version:** Defines the version of the resource.
     - **Kind:** Specifies the type of object (e.g., Deployment, Service).
     - **Metadata:** Contains resource name and labels.
     - **Spec:** Defines the configuration, such as number of replicas, image details, and ports.
   - Ensure proper indentation and key-value formatting in YAML to avoid errors.

## 6. **Exposing Pods to External Networks**
   - A **Service** is required to expose pods to external networks.
     - Types of services include `LoadBalancer`, `NodePort`, or `ExternalName`.
   - Service configuration must specify:
     - `apiVersion`
     - `kind: Service`
     - `metadata: name`
     - `spec: port`, `type` (e.g., LoadBalancer, NodePort)

## 7. **Namespace in Kubernetes**
   - **Namespace** helps in organizing and isolating resources within a cluster based on teams or projects.
     - Example: Different teams (e.g., front-end, back-end) can have their own namespaces.
   - Default namespaces include:
     - `default`
     - `kube-node-lease`
     - `kube-public`
     - `kube-system`
   - Use `kubectl get namespaces` to view all namespaces.

## 8. **Working with Namespaces**
   - **Creating a Namespace:** `kubectl create namespace [namespace name]`.
   - **Listing Resources in a Namespace:** Use `kubectl get [resource] -n [namespace]`.
     - Example: `kubectl get pods -n mynamespace` to list pods in a specific namespace.
   - **Setting Context for Namespace:** 
     - Use `kubectl config set-context --current --namespace=[namespace]` to switch to a specific namespace.
     - To revert, you can set the context back to the desired namespace.

## 9. **Namespace Isolation Example**
   - Example scenario: Team `A` can only see and manage resources within their namespace, while Team `B` can do the same for theirs, maintaining resource isolation within a shared cluster.

---

This structured note provides a summary of key Kubernetes operations, focusing on pod management, deployment methods, service exposure, and the use of namespaces for resource organization.

# DevOps Kubernetes Concepts

## 1. **Namespaces in Kubernetes**
   - **Default Namespace**: When no namespace is specified, deployments are part of the default namespace. If you do not define a specific namespace in your configuration file, it will be assigned to the default namespace.
   - **Organizing Clusters**: Namespaces are used to organize and restrict access to resources in a Kubernetes cluster. They allow multiple teams to work on the same cluster without interference.
   - **Listing Deployments**: Use the command `kubectl get deployment` to view deployments. If no specific namespace is mentioned, it will list resources in the default namespace.
   - **Namespace Management**:
     - **Create Namespace**: You can create a namespace using a YAML file. The YAML file must include basic properties like `apiVersion`, `kind`, and `metadata.name`.
     - **Delete Namespace**: To delete a namespace, use the command `kubectl delete ns <namespace-name>`.

## 2. **Nodes in Kubernetes**
   - **Node Overview**: A Kubernetes cluster is composed of multiple nodes, and each node is responsible for running containerized applications (pods).
   - **Node Affinity & Taints**:
     - **Affinity**: It allows you to specify which nodes can or cannot host your pods, directing where workloads should be placed.
     - **Taints and Tolerations**: Taints are applied to nodes to prevent them from accepting any pods unless they have tolerations that match the taints. This can be useful in scenarios like node failures or maintenance to avoid deploying new pods on certain nodes.

## 3. **Taints and Tolerations**
   - **Applying Taints**: Use `kubectl taint nodes <node-name> <key>=<value>:<effect>` to taint a node. Common effects include:
     - `NoSchedule`: Prevents pods from being scheduled on the node.
     - `PreferNoSchedule`: Soft request to avoid scheduling pods.
     - `NoExecute`: Evicts any running pods and prevents new ones from running.
   - **Removing Taints**: Use `kubectl taint nodes <node-name> <key>:NoSchedule-` to remove a taint (untainting).
   - **Usage Scenarios**: Apply taints in situations like node failure, maintenance, or special-purpose nodes (e.g., reserved for specific workloads).

## 4. **Node Affinity (Anti-Affinity)**
   - **Affinity**: The opposite of taints, used when you want to attract workloads to specific nodes. Node affinity rules specify which nodes are preferred for deployment.
   - **Anti-Affinity**: A strategy to avoid deploying workloads on specific nodes, acting as the opposite of affinity.

## 5. **Horizontal Pod Autoscaler (HPA)**
   - **Overview**: HPA is a feature in Kubernetes that automatically scales the number of pod replicas based on CPU utilization or other custom metrics.
   - **Metrics for Scaling**: HPA operates based on metrics such as CPU utilization. For example, if the CPU usage exceeds 50%, the system automatically increases the number of pods.
   - **Configuration**: 
     - **Metric Server**: Install a metrics server to gather the resource usage data required for scaling decisions.
     - **YAML Configuration**: In the HPA YAML file, you define the target CPU utilization percentage that triggers the scaling.
   - **Commands**:
     - Use `kubectl get hpa` to view autoscaler details.
     - Configure scaling in a YAML file that includes deployment and service files, as well as HPA specifications.

### **Important Commands:**
   - **Get Nodes**: `kubectl get nodes` – Lists all nodes in the cluster.
   - **Describe Pod**: `kubectl describe pod <pod-name>` – Provides detailed information about a pod.
   - **Taint Node**: `kubectl taint nodes <node-name> <key>=<value>:<effect>` – Applies a taint to a node.
   - **Create HPA**: `kubectl apply -f hpa.yaml` – Applies an HPA configuration file.

## 6. **Real-World Use Cases**
   - **Node Failure or Maintenance**: Use taints to prevent new workloads from being scheduled on failing or under-maintenance nodes.
   - **Auto-scaling**: Automatically increase or decrease the number of pods based on resource demands, ensuring high availability and performance of applications.

This summary provides an organized overview of namespaces, nodes, taints, tolerations, affinity, and autoscaling in Kubernetes, along with real-world use cases and essential commands for managing clusters effectively.

Here’s a structured and summarized version of your notes on DevOps, with headings added for clarity:

---

### 1. **Pod Autoscaling in Kubernetes**
   - **Blending Metrics**: When a pod’s CPU or memory usage exceeds 50%, Kubernetes will automatically create additional pods.
   - **Example**: If a pod’s CPU usage exceeds 50% of 500 milliCores (i.e., 250 milliCores), Kubernetes will trigger the creation of another pod.
   - **Scaling Metrics**: When resource consumption hits thresholds like 160 milliCores or 500 milliCores, actions such as adding new pods or deleting existing ones occur.
   
### 2. **Scaling Conditions**
   - **Threshold Values**: If a pod consumes more than 500 milliCores, it may be deleted and a new pod created. This ensures efficient resource utilization.
   - **Auto-scaler Functionality**: Kubernetes auto-scaler adjusts the number of pods based on CPU/memory consumption. For instance, between 1 and 10 pods may be maintained, depending on resource demands.

### 3. **HP Autoscaler Deployment**
   - **Deployment Strategy**: Use Kubernetes commands like `kubectl create -f <file>` to deploy applications. YAML files often contain configurations for deployment, service, and Horizontal Pod Autoscaler (HPA).
   - **Configuring Metrics**: Metrics are collected from each node and used to adjust the number of pods. For example, when usage reaches 80%, additional pods are created.
   - **Virtual Load Testing**: Load generators can be used to simulate increased demand, prompting the auto-scaler to adjust pod counts accordingly.

### 4. **Auto-scaler in Action**
   - **Incremental Scaling**: When resource consumption increases, Kubernetes scales up the pod count. For instance, when CPU consumption reaches 240 milliCores, additional replicas are created.
   - **Consumption Monitoring**: The auto-scaler continuously monitors usage and adjusts pod counts to ensure optimal performance.
   
### 5. **Horizontal Pod Autoscaler (HPA) Configuration**
   - **Threshold Settings**: Configure HPA with threshold values in the Kubernetes manifest file to control scaling actions based on resource consumption.
   - **Pod Lifecycle Management**: If resource usage exceeds predefined limits (e.g., 500 milliCores), pods may be terminated and replaced.

### 6. **Azure DevOps Certification (AZ-400)**
   - **Certification Overview**: AZ-400 focuses on Azure DevOps. The exam assesses knowledge of various DevOps practices, tools, and methodologies.
   - **Certification Details**: The cost of the exam is USD 1625. For candidates in India, the price is approximately INR 4800. Discounts and reimbursements (50%) may be available based on the company’s policies.
   - **Preparation Resources**: Microsoft provides a learning portal and practice tests to help candidates prepare for the AZ-400 certification exam.

### 7. **Cost and Reimbursement for Certification**
   - **Certification Costs**: In India, employees may need to pay INR 2400 plus GST for the certification, which is 50% of the total cost.
   - **Reimbursement Policies**: To qualify for 100% reimbursement, candidates may need to consult with their manager or HR department based on business requirements.

### 8. **Additional Information**
   - **Practice Tests**: Microsoft offers practice tests and knowledge checks for each stage of preparation, helping candidates assess their readiness for the exam.
   - **Exam Scheduling**: Exams can be scheduled through the official Microsoft certification portal.

### 9. **Q&A and Discussions**
   - **Open Questions**: Participants are encouraged to ask questions related to the certification, DevOps practices, or the implementation of pod autoscaling in Kubernetes.

---

This summarized version includes key points from the original transcript with clear headings to organize the content into distinct sections. Let me know if you need further details!

### Kubernetes and Container Management in Azure

**Introduction:**
Kubernetes is a powerful container orchestration tool that manages containers across multiple nodes. This platform ensures scalability, high availability, and automation in deployment, making it essential for modern cloud environments. 

**Azure DevOps Artifacts and Test Plans:**
- **Artifacts:** Azure DevOps provides a built-in repository (Artifactory) for storing packages and build outputs, up to 2GB for free. You can increase the limit if needed.
- **Test Plans:** Azure DevOps allows users to write and run test cases manually or integrate them with automation tools. These test plans help to monitor the success or failure of tests.

**Steps for Enabling Test Plans:**
1. Navigate to **Project Settings** -> **Test Management**.
2. Configure basic users and add test plans to your project.
3. Assign tests to specific users and manage test execution statuses.

---

### Kubernetes Cluster Setup in Azure

**Kubernetes Overview:**
Kubernetes automates container deployment, scaling, and management across clusters. It handles tasks like load balancing, failover, rolling updates, and rollback without downtime.

**Supported Platforms:**
- **AWS:** Elastic Kubernetes Service (EKS)
- **Azure:** Azure Kubernetes Service (AKS)
- **Google Cloud:** Google Kubernetes Engine (GKE)

**Creating a Kubernetes Cluster in Azure:**
1. **Choose Resource Group:**
   - Assign a name like `AKS` for the Azure Kubernetes Service.
   
2. **Select Environment:**
   - Options: Development, Testing, Production.
   - Example: Choose **Dev and Test** for non-production environments.

3. **Pricing Tier:**
   - **Free Tier:** Kubernetes master is free, but nodes are paid based on the number and size.
   
   ```yaml
   Pricing: Free
   ```

4. **Kubernetes Version:**
   - Choose the desired Kubernetes version (e.g., 1.29.2).
   
5. **Security Configuration:**
   - Enable security patches and node image updates.
   - Set up periodic security audits.

6. **Agent Pool Configuration:**
   - Choose the agent pool type based on your needs (e.g., `Standard DS` for general purposes).
   - Example configuration for 2 nodes with 110 pods per node:
   
   ```yaml
   Max Pods per Node: 110
   Nodes: 2
   ```

7. **Network Configuration:**
   - **Azure CNI**: Suitable for small clusters, where each pod gets a unique IP address.
   - **Network Policy:** Configure network policies (e.g., Calico) to manage traffic between pods.

8. **Private/Public Access:**
   - **Public:** Accessible over the internet with IP whitelisting.
   - **Private:** Restricted to internal networks.

---

### Kubernetes Master and Node Components

**Master Components:**
- **Scheduler:** Allocates pods to nodes.
- **Controller Manager:** Ensures the desired number of pod replicas are running.
- **API Server:** Manages all Kubernetes API requests.

**Node Components:**
- **kubelet:** Agent running on each node, reporting status and managing pod lifecycle.
- **kube-proxy:** Manages network communications between nodes and pods using TCP/UDP.

---

### Deployment Management in Kubernetes

**Deployments:**
Kubernetes allows for zero-downtime updates and rollbacks. You can scale up or down the number of pods dynamically, ensuring that applications remain available under varying load conditions.

**Pod Scaling Example:**
To scale a deployment to 3 replicas:
```bash
kubectl scale deployment my-app --replicas=3
```

**Rollback Example:**
If a new deployment fails, you can rollback to the previous version:
```bash
kubectl rollout undo deployment/my-app
```

---

### Cluster Authentication and Connectivity

**Connecting to Azure Kubernetes Cluster:**
1. Use Azure Cloud Shell or your local CLI:
   ```bash
   az aks get-credentials --resource-group myResourceGroup --name myAKSCluster
   ```

2. Install necessary tools:
   - **Azure CLI** and **kubectl** for managing the Kubernetes cluster.

---

This is a high-level overview of using Kubernetes within Azure, managing test plans and artifacts in Azure DevOps, and understanding key components involved in cluster management.

### DevOps Notes - Kubernetes Commands & Concepts

#### 1. **Kubernetes CLI Setup**
   - Ensure that `kubectl` (Kubernetes Command Line Interface) is installed on your system.
   - For environments like Azure Cloud Shell, `kubectl` comes pre-installed.

   ```bash
   kubectl version  # Check the version of kubectl installed
   ```

#### 2. **Nodes and Cluster**
   - A Kubernetes cluster contains multiple nodes. A node is a worker machine where containers are deployed.
   - Each node in a cluster can have a specific number of **pods** it can handle. The default pod count for a node is 110.

   **Commands to interact with nodes:**
   ```bash
   kubectl get nodes  # List all nodes in the cluster
   kubectl describe node <node-name>  # Detailed information about a specific node
   ```

#### 3. **Node Labels**
   - Kubernetes nodes have **labels** which contain metadata like OS type, architecture, and storage types.
   - You can fetch these labels using:
   
   ```bash
   kubectl get nodes --show-labels  # Show labels for each node
   ```

#### 4. **Imperative vs Declarative Approaches**
   - **Imperative**: Directly running commands to create resources.
     - Example: Running a command to create a deployment.
   - **Declarative**: Defining the desired state in a YAML manifest file.
     - Example: Writing a YAML file to specify how your deployment should behave.

#### 5. **Interacting with Pods and Deployments**
   - Pods are the smallest deployable units in Kubernetes.
   - A **deployment** is used to manage a set of pods.

   **Commands to interact with deployments:**
   ```bash
   kubectl get pods         # List all pods in the default namespace
   kubectl get deployment   # List deployments in the cluster
   kubectl describe deployment <deployment-name>  # Get detailed info of a specific deployment
   ```

#### 6. **Creating a Deployment**
   - A deployment specifies the **Docker image**, the **replicas** (number of pod copies), and the **port**.
   
   **Example Command:**
   ```bash
   kubectl create deployment my-deployment --image=nginx --replicas=5  # Creates a deployment with 5 replicas of nginx
   ```

   **Sample Deployment YAML:**
   ```yaml
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: my-deployment
   spec:
     replicas: 5
     selector:
       matchLabels:
         app: my-app
     template:
       metadata:
         labels:
           app: my-app
       spec:
         containers:
         - name: nginx
           image: nginx
           ports:
           - containerPort: 80
   ```

#### 7. **Running and Exposing the Deployment**
   - Once the deployment is created, you can run it and expose it using a **service**.
   - Services are responsible for exposing the pods to external traffic or internal cluster communication.

   **Command to expose deployment:**
   ```bash
   kubectl expose deployment my-deployment --type=LoadBalancer --port=80
   ```

   - Service Types:
     - **ClusterIP**: Internal communication within the cluster.
     - **NodePort**: Exposes the service on each node’s IP at a static port.
     - **LoadBalancer**: Exposes the service to the internet (used in cloud environments).

#### 8. **Accessing the Application**
   - If using a **LoadBalancer** service, get the external IP and access your application.
   
   ```bash
   kubectl get services  # Shows service details, including external IPs for LoadBalancer services
   ```

#### 9. **Useful Commands**
   - **Get all resources**: 
     ```bash
     kubectl get all  # Fetch all resources like pods, deployments, services, etc.
     ```
   - **Get detailed information** about resources:
     ```bash
     kubectl describe <resource> <name>  # Get detailed info about a specific resource like pods, services, deployments
     ```

### Summary of Key Concepts:
- Use `kubectl` to manage Kubernetes clusters, nodes, pods, deployments, and services.
- Kubernetes supports **imperative** (commands) and **declarative** (YAML files) management styles.
- Services are crucial to expose your deployment, with different types (ClusterIP, NodePort, LoadBalancer).
- The deployment manages pods, replicas, and other configurations, while services manage communication.

### DevOps Kubernetes Commands Summary

#### 1. **Getting Pod Information**
   - To retrieve detailed information about a specific pod, use the `describe` command:
     ```bash
     kubectl describe pod <pod_name>
     ```
     This will provide details such as:
     - Pod IP address
     - Current status
     - Start time
     - Node where the pod is running
     - Associated services
     - Status messages (e.g., successful image pulls)

#### 2. **Viewing Logs of a Pod**
   - To view the logs of a pod, use the following command:
     ```bash
     kubectl logs <pod_name>
     ```
     This will fetch all logs related to the specific pod.

#### 3. **Viewing Events**
   - To see the events happening in the Kubernetes cluster, use:
     ```bash
     kubectl get events
     ```
     This command provides information about various stages that occurred in the cluster.

#### 4. **Imperative vs Declarative Deployment**
   - **Imperative Method**: Directly applying commands to deploy resources.
     ```bash
     kubectl create deployment nginx --image=nginx
     ```
     Drawback: Lack of reusability and hard to manage configuration across environments.
     
   - **Declarative Method**: Using configuration files (e.g., YAML) to deploy resources. This is the preferred method for production environments due to better manageability and reusability.
     - Example of a basic **Deployment YAML**:
       ```yaml
       apiVersion: apps/v1
       kind: Deployment
       metadata:
         name: d2
       spec:
         replicas: 2
         selector:
           matchLabels:
             app: myapp
         template:
           metadata:
             labels:
               app: myapp
           spec:
             containers:
             - name: nginx
               image: nginx
               ports:
               - containerPort: 80
       ```

#### 5. **Running YAML Files**
   - Apply the declarative YAML file using the following command:
     ```bash
     kubectl apply -f <file_name>.yaml
     ```
   - You can also use `kubectl create -f <file_name>.yaml` to create resources.

#### 6. **Services for Exposing Applications**
   - To expose an application to the outside network, a service is required. For instance:
     ```yaml
     apiVersion: v1
     kind: Service
     metadata:
       name: my-service
     spec:
       type: LoadBalancer
       ports:
       - port: 80
       selector:
         app: myapp
     ```

#### 7. **Namespaces**
   - **Namespace** helps in organizing resources in a Kubernetes cluster. By default, all resources are in the `default` namespace.
     - List all namespaces:
       ```bash
       kubectl get namespaces
       ```
     - Create a new namespace:
       ```bash
       kubectl create namespace <namespace_name>
       ```
     - View resources in a specific namespace:
       ```bash
       kubectl get deployments -n <namespace_name>
       ```

#### 8. **Common YAML Structure**
   All Kubernetes YAML files should include the following properties:
   - `apiVersion`: Defines the API version (e.g., apps/v1).
   - `kind`: Specifies the type of resource (e.g., Deployment, Service).
   - `metadata`: Contains the name and labels for the resource.
   - `spec`: Provides the specification for the resource, including replicas, containers, and images.

### Summary of Key Concepts
- Use `kubectl describe` for pod details.
- Fetch logs using `kubectl logs <pod_name>`.
- Manage events with `kubectl get events`.
- Apply YAML configuration files for declarative deployments.
- Namespace isolation allows team-specific resource access.

## DevOps Notes: Namespace, Taints, and Auto-scaling in Kubernetes

### 1. **Namespaces in Kubernetes**

- **Default Namespace**: If no specific namespace is defined in the configuration, the application will be part of the default namespace.
- **Use Case of Namespaces**:
  - Organizing resources in clusters.
  - Restricting access for different teams.
  - Namespaces can be used to limit access to specific teams working within a shared cluster.
  
- **Listing and Switching Namespaces**:
  - You can switch to a specific namespace using the following command:
    ```bash
    kubectl config set-context --current --namespace=<namespace-name>
    ```
  
- **Creating a Namespace with YAML**:
  - You can define a namespace using a YAML file with properties like `apiVersion`, `kind`, and `metadata`.
    ```yaml
    apiVersion: v1
    kind: Namespace
    metadata:
      name: my-namespace
    ```
  - To create a namespace:
    ```bash
    kubectl create -f namespace.yaml
    ```
  
- **Deleting a Namespace**:
  ```bash
  kubectl delete namespace <namespace-name>
  ```

### 2. **Taints and Tolerations**

- **Taints**: Used to prevent pods from being scheduled on specific nodes.
- **Use Case**: You can taint nodes to avoid deploying applications on them if they are reserved for specific purposes or undergoing maintenance.
  
- **Applying Taints**:
  ```bash
  kubectl taint nodes <node-name> key=value:NoSchedule
  ```
  - `NoSchedule`: Prevents scheduling of pods on the tainted node.
  - `PreferNoSchedule`: Indicates a preference not to schedule on the node but does not strictly enforce it.
  - `NoExecute`: Evicts already running pods from the tainted node.

- **Removing Taints**:
  ```bash
  kubectl taint nodes <node-name> key=value:NoSchedule-
  ```

### 3. **Node Affinity**

- **Node Affinity**: Used to attract pods to be scheduled on specific nodes.
- **Opposite of Taints**: While taints prevent scheduling on a node, node affinity ensures that the pods are scheduled on specific nodes.
  
- **Example**:
  ```yaml
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: <key>
            operator: In
            values:
            - <value>
  ```

### 4. **Horizontal Pod Autoscaler (HPA)**

- **Autoscaling Concept**: HPA automatically scales the number of pods in a deployment based on observed CPU utilization or other metrics.
- **Key Steps**:
  1. **Install Metric Server**:
     ```bash
     kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
     ```
  2. **Create HPA YAML Configuration**:
     ```yaml
     apiVersion: autoscaling/v1
     kind: HorizontalPodAutoscaler
     metadata:
       name: hpa-example
     spec:
       scaleTargetRef:
         apiVersion: apps/v1
         kind: Deployment
         name: nginx-deployment
       minReplicas: 1
       maxReplicas: 10
       targetCPUUtilizationPercentage: 50
     ```
     This configuration will increase pod count when CPU utilization exceeds 50%.
  
  3. **Check HPA Status**:
     ```bash
     kubectl get hpa
     ```

### 5. **Common Commands**
- **List Nodes**:
  ```bash
  kubectl get nodes
  ```
  
- **List Pods**:
  ```bash
  kubectl get pods
  ```
  
- **Describe Pods**:
  ```bash
  kubectl describe pod <pod-name>
  ```

### 6. **Practical Use Cases**
- **When to Apply Taints**:
  - Nodes in maintenance mode.
  - Nodes reserved for specific applications.
  - To prevent deployment of pods in nodes with insufficient resources.
  
- **When to Remove Taints**:
  - Once the node is ready for use again (post-maintenance).
  
- **Auto-scaling Scenarios**:
  - When CPU utilization crosses a certain threshold, additional pods are automatically added to balance the load.

### 7. **Affinity and Anti-Affinity**
- **Node Affinity**: Attracts pods to specific nodes based on defined rules.
- **Anti-Affinity**: Ensures pods do not run on specific nodes.

By using namespaces, taints, node affinity, and auto-scaling, Kubernetes allows for efficient resource management, security, and performance optimization.

Here’s a summary of your transcript in a structured and readable format, along with relevant headings and code snippets where appropriate.

---

# DevOps Autoscaling and Horizontal Pod Autoscaler (HPA)

## Overview of Pod Autoscaling

- **Autoscaling** is a critical concept in DevOps, ensuring that applications automatically scale based on their resource consumption.
- Horizontal Pod Autoscaler (HPA) dynamically adjusts the number of pods in a Kubernetes cluster based on observed CPU or memory usage.

### Key Metrics for Autoscaling
- When a pod reaches a specified CPU threshold (e.g., 50%), Kubernetes automatically launches additional pods.
- **Example**: If CPU usage crosses 50% of a core or 250,000,000 cores, a new pod is created to handle the load.
- If the CPU consumption exceeds 500 million cores, the pod will crash, and Kubernetes will restart it.

```yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-example
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80
```

### Scaling Scenarios
- **Threshold Example**: When CPU usage hits 160 milli-core (or 80% of the total available), a new pod is created.
- **Limit Scenario**: If usage surpasses 500 milli-core, the current pod is deleted, and a new pod is initiated.

### Autoscaling Logic
- **Minimum Pods**: Set the minimum number of replicas to 1.
- **Maximum Pods**: The maximum can be set up to 10 based on resource utilization.
- The pod count will dynamically increase or decrease depending on the load.

## Deploying an Application with Autoscaling

To deploy an application using HPA, ensure that the necessary YAML files are configured for deployment, service, and autoscaling.

1. **Deployment YAML File**: Contains the application configuration.
2. **Service YAML File**: Defines how the application will be exposed.
3. **HPA YAML File**: Configures autoscaling behavior based on resource usage.

```bash
kubectl create -f hpa-example.yaml
kubectl get hpa
```

The command `kubectl get hpa` will show the status of your HPA, including metrics and scaling behavior.

### Load Generation for Testing Autoscaling

You can simulate a load to trigger the autoscaler using a load generator:

```bash
kubectl run -i --tty load-generator --image=busybox /bin/sh
# Inside the pod, run the following command to create load
while true; do wget -q -O- http://my-app; done
```

As the load increases, the HPA will scale the application by adding more pods.

---

# Azure DevOps Certification (AZ-400)

The transcript also touches on the **Azure DevOps Certification (AZ-400)**:

- **Certification Name**: Microsoft Certified: Azure DevOps Engineer Expert.
- **Exam Cost**: Approx. USD 1625 (for non-India residents). For India, it’s approximately INR 4800.
- **Company Reimbursement**: At NielsenIQ, associates may get up to 50% reimbursement (you need to check with your manager for additional coverage).

### Resources
- You can access the Azure learning portal for further study and practice tests.
  
---

This summary includes key concepts and practical steps related to **Kubernetes autoscaling**, as well as information about the **Azure DevOps certification**.